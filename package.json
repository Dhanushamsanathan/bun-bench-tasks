{
  "name": "bun-bench-tasks",
  "version": "1.0.0",
  "description": "Synthetic benchmark tasks for evaluating AI on Bun.js",
  "module": "index.ts",
  "type": "module",
  "private": true,
  "scripts": {
    "test:task": "cd tasks/$TASK && bun test",
    "test:all": "for dir in tasks/task-*; do echo \"Testing $dir...\"; cd $dir && bun test 2>/dev/null || true; cd ../..; done",
    "test:solutions": "bun run scripts/test-solutions.ts",
    "validate": "bun run scripts/validate-tasks.ts",
    "validate-results": "bun run scripts/validate-results.ts",
    "list": "ls -1 tasks/",
    "benchmark": "bun run scripts/run-benchmark.ts",
    "benchmark:verbose": "bun run scripts/run-benchmark.ts --verbose",
    "benchmark:prompt": "bun run scripts/run-benchmark.ts --show-prompt",
    "view-prompts": "bun run scripts/view-prompts.ts",
    "inference": "bun run scripts/run-inference.ts",
    "evaluate": "bun run scripts/run-evaluation.ts",
    "report": "bun run scripts/generate-report.ts"
  },
  "devDependencies": {
    "@types/bun": "latest"
  },
  "peerDependencies": {
    "typescript": "^5"
  },
  "keywords": ["bun", "benchmark", "ai", "evaluation", "testing"],
  "license": "MIT",
  "dependencies": {
    "openai": "^6.21.0"
  }
}
