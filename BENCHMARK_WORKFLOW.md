# ğŸš€ New Benchmark Workflow Guide

## What's New?

**Task-by-task completion** with **intelligent retry** based on real test errors.

---

## ğŸ“Š Workflow Comparison

### Old Way (Two-Phase)
```
Phase 1: Run inference on ALL tasks
  â†’ Saves all AI responses
  â†’ No test feedback

Phase 2: Run evaluation on ALL tasks
  â†’ Tests all responses
  â†’ No retry with feedback
```

### New Way (Task-by-Task)
```
For EACH task:
  1. Attempt 1: Generate fix â†’ Test
  2. If failed â†’ Attempt 2: Generate fix (with error feedback) â†’ Test
  3. If failed â†’ Attempt 3: Generate fix (with all errors) â†’ Test
  4. If still failed â†’ Skip to next task
  5. If passed â†’ Move to next task âœ“
```

---

## ğŸ¯ Key Improvements

### 1. Test-Based Retry (Not Just Syntax)
- **Old**: Retry only on syntax errors
- **New**: Retry on ANY test failure with detailed error messages

### 2. Error Feedback Loop
- AI sees exactly what went wrong:
  ```
  **Error Type:** test_failure
  **Tests:** 2/5 passed
  **Error Details:**
  expected "olleH" but got "hello"
  ```

### 3. Complete One Task Before Moving On
- Ensures quality over quantity
- Better progress tracking
- Can stop/resume anytime

---

## ğŸ“ Usage

### Run Complete Benchmark
```bash
# Process all 80 tasks with intelligent retry
bun run benchmark all
```

### Run Specific Tasks
```bash
# Run specific tasks
bun run benchmark task-001-content-length task-002-json-content-type
```

### Resume from Where You Left Off
```bash
# Automatically skips completed tasks
bun run benchmark all
```

---

## ğŸ“Š Output Format

```
============================================================
Task 1/80: task-001-content-length
============================================================

[task-001-content-length]
  ğŸ”„ Attempt 1/3
  ğŸ“¡ AI Response (15000ms, 1234 tokens)
  ğŸ“ Found 1 file(s) to fix
  ğŸ§ª Running tests...
  âŒ FAILED - test_failure [2/5 tests]
     Error: Expected "olleH" but got "hello"

  ğŸ”„ Attempt 2/3
  ğŸ“¡ AI Response (12000ms, 1100 tokens)
  ğŸ“ Found 1 file(s) to fix
  ğŸ§ª Running tests...
  âœ… PASSED (150ms) [5/5 tests]

============================================================
Task 2/80: task-002-json-content-type
============================================================
```

---

## ğŸ¯ Features

âœ… **Task-by-task completion** - Done
âœ… **Test-based retry** - Real errors, not just syntax
âœ… **Error feedback loop** - AI learns from mistakes
âœ… **Max 3 attempts** - Then skip
âœ… **Skip completed tasks** - Resume support
âœ… **Progress tracking** - Clear console output
âœ… **Source preservation** - Restores original code after each test

---

## ğŸ“ Files

### New Script
- `scripts/run-benchmark.ts` - Main workflow (recommended)

### Existing Scripts (Still Work)
- `scripts/run-inference.ts` - Standalone inference
- `scripts/run-evaluation.ts` - Standalone evaluation

---

## ğŸ’¡ When to Use Each Script

### Use `bun run benchmark` (Recommended)
- Running full benchmark
- Want intelligent retry with test feedback
- Task-by-task progress

### Use `bun run inference` + `bun run evaluate`
- Already have some results
- Want to run in two phases
- Don't need retry feedback

---

## ğŸ”§ How It Works

### 1. Read Task Files
```
- README.md (problem description)
- src/*.ts (buggy code)
```

### 2. First Attempt
```typescript
// Prompt: README + buggy code
â†’ AI generates fix
â†’ Apply fix
â†’ Run tests
â†’ Pass? âœ“ Done
â†’ Fail? Continue â†’
```

### 3. Second Attempt (With Feedback)
```typescript
// Prompt: README + buggy code + ERROR MESSAGE
â†’ AI sees what went wrong
â†’ AI generates improved fix
â†’ Apply fix
â†’ Run tests
â†’ Pass? âœ“ Done
â†’ Fail? Continue â†’
```

### 4. Third Attempt (With All Errors)
```typescript
// Prompt: README + buggy code + ALL PREVIOUS ERRORS
â†’ AI sees full error history
â†’ AI generates final fix
â†’ Apply fix
â†’ Run tests
â†’ Pass? âœ“ Done
â†’ Fail? â­ï¸ Skip to next task
```

---

## ğŸ“ˆ Progress Tracking

The script shows:
- Current task number (X/80)
- Attempt number (1/3, 2/3, 3/3)
- AI response time and token usage
- Test results (passed/total)
- Error type and details
- Final status (âœ… PASSED or â­ï¸ Skipped)

---

## â­ï¸ Skipping Logic

Tasks are skipped if:
1. Already passed (has evaluation-result.json with passed: true)
2. Failed all 3 attempts

---

## ğŸ”„ Resume Capability

```bash
# Run 20 tasks, then stop (Ctrl+C)
bun run benchmark all

# Later, resume - it will skip the 20 completed tasks
bun run benchmark all
```

---

## ğŸ’¾ Output Files

For each task:
- `inference-response.json` - AI's final response
- `evaluation-result.json` - Test results

---

## ğŸ‰ Summary

After completion:
```
============================================================
BENCHMARK SUMMARY
============================================================
Passed:   45 âœ…
Failed:   25 âŒ
Skipped:  10 â­ï¸
Success:  64.3%
============================================================
```

---

**Status**: âœ… Ready to use
**Version**: 2.0
**Command**: `bun run benchmark all`
